{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0ab80297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q qpsolvers proxsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dcaf329c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, re, math\n",
    "from pathlib import Path\n",
    "from typing import List, Dict\n",
    "from qpsolvers import solve_qp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "efb2bffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "SparseVec = Dict[int, float]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0e959f",
   "metadata": {},
   "source": [
    "# 0. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0b33d2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = re.compile(r\"[A-Za-z][A-Za-z0-9_']+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "332ae64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_first4(text):\n",
    "    lines = text.splitlines()\n",
    "    return \"\\n\".join(lines[4:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9a53e7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    return [t.lower() for t in token.findall(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0cac5b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readtoken(path):\n",
    "    with open(path, \"r\", encoding = \"utf-8\", errors = \"ignore\") as f:\n",
    "        txt = f.read()\n",
    "    \n",
    "    return tokenize(strip_first4(txt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8f68b9",
   "metadata": {},
   "source": [
    "# 1.  Data Refining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "13766f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_class_files(root):\n",
    "    out = {}\n",
    "    for p in sorted(Path(root).iterdir()):\n",
    "        if p.is_dir():\n",
    "            files = sorted([str(fp) for fp in p.iterdir() if fp.is_file()])\n",
    "            if files:\n",
    "                out[p.name] = files\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f206193",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_half_split(paths_labels, seed = 42):\n",
    "    rng = random.Random(seed)\n",
    "    train, test = {}, {}\n",
    "    labels = sorted(paths_labels.keys())\n",
    "    for label in labels:\n",
    "        lst = list(paths_labels[label])\n",
    "        rng.shuffle(lst)\n",
    "        k = len(lst) // 2\n",
    "        train[label] = lst[:k]\n",
    "        test[label] = lst[k:]\n",
    "    \n",
    "    return train, test, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cb4a06",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e68af4f",
   "metadata": {},
   "source": [
    "# 2. TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "90f557f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf(train_paths):\n",
    "    total_tf = {}\n",
    "    df = {}\n",
    "    n_docs = 0\n",
    "    for files in train_paths.values():\n",
    "        for path in files:\n",
    "            toks = readtoken(path)\n",
    "            if not toks:\n",
    "                continue\n",
    "            n_docs += 1\n",
    "            check = set()\n",
    "            for t in toks:\n",
    "                total_tf[t] = total_tf.get(t, 0) + 1\n",
    "                if t not in check:\n",
    "                    df[t] = df.get(t, 0) + 1\n",
    "                    check.add(t)\n",
    "    \n",
    "    if n_docs == 0:\n",
    "        raise ValueError(\"No training documents found\")\n",
    "    \n",
    "    stop = sorted(total_tf.items(), key = lambda kv: kv[1], reverse = True)[:300]\n",
    "    ban = {w for w, _ in stop}\n",
    "\n",
    "    voca = [t for t, cnt in df.items() if t not in ban]\n",
    "    voca.sort()\n",
    "    voca = {t:i for i , t in enumerate(voca)}\n",
    "\n",
    "    idf = np.zeros(len(voca))\n",
    "    for t, i in voca.items():\n",
    "        idf[i] = math.log(n_docs / max(1, df.get(t, 1)))\n",
    "    \n",
    "    return voca, idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9cae0ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_token(tokens, voca, idf):\n",
    "    tf = {}\n",
    "    for t in tokens:\n",
    "        idx = voca.get(t)\n",
    "        if idx is not None:\n",
    "            tf[idx] = tf.get(idx, 0) + 1\n",
    "    if not tf:\n",
    "        return {}\n",
    "    \n",
    "    #log TF(log(1+tf)) * idf\n",
    "    vec: SparseVec = {}\n",
    "    for idx, cnt in tf.items():\n",
    "        val = math.log1p(cnt) * float(idf[idx])\n",
    "        if val != 0.0:\n",
    "            vec[idx] = val\n",
    "\n",
    "    #norm\n",
    "    norm = math.sqrt(sum(v*v for v in vec.values()))\n",
    "    if norm > 0:\n",
    "        for k in list(vec.keys()):\n",
    "            vec[k] /= norm\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bdce1be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(label_paths, voca, idf, labelname):\n",
    "    doc_vec =[]\n",
    "    label_id = []\n",
    "\n",
    "    for lab_idx, lab in enumerate(labelname):\n",
    "        files = label_paths.get(lab, [])\n",
    "        for path in files:\n",
    "            tokens = readtoken(path)\n",
    "            vec = tfidf_token(tokens, voca, idf)\n",
    "            doc_vec.append(vec)\n",
    "            label_id.append(lab_idx)\n",
    "\n",
    "    return doc_vec, label_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8770926a",
   "metadata": {},
   "source": [
    "# 3. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "41ca4b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM:\n",
    "    def __init__(self, c= 100.0, degree = 2, coef= 0.0, tol = 1e-8, solver = \"proxqp\"):\n",
    "        self.c = float(c)\n",
    "        self.degree = int(degree)\n",
    "        self.coef = float(coef)\n",
    "        self.tol = float(tol)\n",
    "        self.solver = solver\n",
    "\n",
    "        self.alphas = None\n",
    "        self.b = 0.0\n",
    "        self.x_train = []\n",
    "        self.y_train = None\n",
    "    \n",
    "\n",
    "    @staticmethod\n",
    "    def sparse_dot(a, b):\n",
    "        if len(a) > len(b):\n",
    "            a, b = b, a\n",
    "        s = 0.0\n",
    "\n",
    "        for i, va in a.items():\n",
    "            s += va * b.get(i, 0.0)\n",
    "        return s\n",
    "        \n",
    "    def dot(self,a ,b):\n",
    "        if isinstance(a, dict) and isinstance(b, dict):\n",
    "            return self.sparse_dot(a, b)\n",
    "        a_arr = np.asarray(a, dtype=  float)\n",
    "        b_arr = np.asarray(b, dtype= float)\n",
    "        return float(np.dot(a_arr, b_arr))\n",
    "\n",
    "\n",
    "    def kernel(self, xi, xj):\n",
    "        return (self.dot(xi, xj) + self.coef) ** self.degree\n",
    "\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        X = list(x)\n",
    "        y = np.asarray(list(y), dtype = float)\n",
    "        n = len(X)\n",
    "        if n== 0:\n",
    "            raise ValueError(\"x is empty\")\n",
    "        if n!= len(y):\n",
    "            raise ValueError(f\"len(x) = {n}, len(y) = {len(y)}\")\n",
    "\n",
    "        if not all(yi in (-1.0, 1.0) for yi in y):\n",
    "            raise ValueError(\"y mist be in {-1.0, 1.0}\")\n",
    "\n",
    "        #1. 커널 행렬\n",
    "        K = np.empty((n, n), dtype = float)\n",
    "        for i in range(n):\n",
    "            for j in range(i, n):\n",
    "                kij = self.kernel(X[i], X[j])\n",
    "                K[i, j] = kij\n",
    "                K[j, i] = kij\n",
    "        \n",
    "\n",
    "        #2. QP -> min 0.5 a^T P a + q^T a\n",
    "        #P =  ((y.reshape(-1, 1) @ y.reshape(-1, 1)) * K).astype(np.float64)\n",
    "        #P = 0.5 * (P+ P.T)\n",
    "        #P.flat[:: P.shape[0] + 1] += 1e-10\n",
    "        Y = y.reshape(-1, 1)\n",
    "        P = (Y @ Y.T) * K\n",
    "        P = P.astype(np.float64)\n",
    "        P = 0.5 * (P+ P.T)\n",
    "        P.flat[:: P.shape[0] + 1] += 1e-10\n",
    "\n",
    "        q = -np.ones(n, dtype=np.float64)\n",
    "\n",
    "        #3. 제약 (Box + Inequality)\n",
    "        I = np.eye(n, dtype=np.float64)\n",
    "        G = np.vstack([I, -I])\n",
    "        h = np.hstack((np.full(n, self.c), np.zeros(n))).astype(np.float64)\n",
    "    \n",
    "\n",
    "        A = y.reshape(1, -1).astype(np.float64)\n",
    "        b = np.array([0.0], dtype=np.float64)\n",
    "\n",
    "\n",
    "\n",
    "        #4., QP 풀이\n",
    "        alphas = solve_qp(P, q, G, h, A, b, solver = self.solver)\n",
    "        if alphas is None:\n",
    "            raise RuntimeError(\"QP solver returned None\")\n",
    "        alphas = np.asarray(alphas, dtype = np.float64).ravel()\n",
    "\n",
    "        #5. SV 추출 (alpha> tol)\n",
    "        sv_mask = alphas > self.tol\n",
    "        self.alphas=  alphas[sv_mask]\n",
    "        self.x_train = [X[i] for i in np.where(sv_mask)[0]]\n",
    "        self.y_train = y[sv_mask]\n",
    "\n",
    "        margin_mask = (alphas > self.tol) & (alphas < self.c - self.tol)\n",
    "        idx_for_b = np.where(margin_mask)[0]\n",
    "\n",
    "        if idx_for_b.size == 0:\n",
    "            idx_for_b = np.where(sv_mask)[0]\n",
    "\n",
    "        b_vals = []\n",
    "        for i in idx_for_b:\n",
    "            s = 0.0\n",
    "            xi = X[i]\n",
    "            for a_j, y_j, xj in zip(self.alphas, self.y_train, self.x_train):\n",
    "                s += a_j * y_j * self.kernel(xj, xi)\n",
    "            b_vals.append(y[i] - s)\n",
    "        self.b = float(np.mean(b_vals)) if b_vals else 0.0\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    def decision(self, X):\n",
    "        scores = []\n",
    "        for x in X:\n",
    "            s = 0.0\n",
    "            for a_j, y_j, x_j in zip(self.alphas, self.y_train, self.x_train):\n",
    "                s += a_j * y_j * self.kernel(x_j, x)\n",
    "            scores.append(s + self.b)\n",
    "\n",
    "        return np.asarray(scores, dtype = float)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return [1.0 if v >= 0.0 else -1.0 for v in self.decision(X)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5b68f6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class onevall:\n",
    "    def __init__(self, c = 100.0, degree = 2, coef = 0.0, tol = 1e-6, solver = \"proxqp\"):\n",
    "        self.parameters = dict(c=c, degree=degree, coef=coef, tol=tol)\n",
    "        self.models = []\n",
    "        self.classes = None\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        labels = sorted(set(y))\n",
    "        self.classes = labels\n",
    "        self.models = []\n",
    "        for k in labels:\n",
    "            yk = [1.0 if yi == k else -1.0 for yi in y]\n",
    "            classifier = SVM(**self.parameters).fit(x, yk)\n",
    "            self.models.append(classifier)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def decision(self, x):\n",
    "        scores = np.column_stack([m.decision(x) for m in self.models])\n",
    "        return scores\n",
    "    \n",
    "    def predict(self, x):\n",
    "        scores = self.decision(x)\n",
    "        idx = np.argmax(scores, axis=1)\n",
    "        \n",
    "        return [self.classes[i] for i in idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1c623b",
   "metadata": {},
   "source": [
    "# 4. Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "749c8b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline(root, seed = 42):\n",
    "    paths = list_class_files(root)\n",
    "    train_path, test_path, label_names = stratified_half_split(paths, seed=seed)\n",
    "    voca, idf = tf_idf(train_path)\n",
    "    x_train, y_train = vectorize(train_path, voca, idf, label_names)\n",
    "    x_test, y_test = vectorize(test_path, voca, idf, label_names)\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test, voca, idf, label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "18de6d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accurrate(y_true, y_pred):\n",
    "    return sum(int(a==b) for a, b in zip(y_true, y_pred)) / len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "664175e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Linear] Accuracy = 0.8801\n",
      "[Poly d=2] Accuracy = 0.8581\n"
     ]
    }
   ],
   "source": [
    "root = \"/Users/gwaec/umd_lectures_projects/cmsc422/hw2/20_newsgroups\"\n",
    "x_train, y_train, x_test, y_test, voca, idf, labels = run_pipeline(root)\n",
    "\n",
    "linear = onevall(c=100.0, degree=1, coef=0.0, solver = \"proxqp\").fit(x_train, y_train)\n",
    "linear_accurracy = accurrate(y_test, linear.predict(x_test))\n",
    "print(f\"[Linear] Accuracy = {linear_accurracy:.4f}\")\n",
    "\n",
    "poly = onevall(c=100.0, degree=2, coef=0.0, solver = \"proxqp\").fit(x_train, y_train)\n",
    "poly_accurracy = accurrate(y_test, poly.predict(x_test))\n",
    "print(f\"[Poly d=2] Accuracy = {poly_accurracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
